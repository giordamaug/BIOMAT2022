# -*- coding: utf-8 -*-
"""NodeClassificaytion.ipynb



Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NbmTr3i8M5BIn9UkOuNEY4xP81_EbbZh
"""
from ast import literal_eval

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    
import warnings
warnings.filterwarnings('ignore')
import random
import pandas as pd
def set_seed(seed=1):
    random.seed(seed)
    np.random.seed(seed)
import argparse
from operator import index
import numpy as np
from tqdm import tqdm
import pandas as pd
import os
from collections import Counter

from sklearn.preprocessing import LabelEncoder
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.compose import make_column_transformer
from sklearn.pipeline import make_pipeline
from sklearn.compose import make_column_selector as selector
from sklearn.neural_network import MLPClassifier
from sklearn.linear_model import RidgeClassifier
import sys
from xgboost import XGBClassifier
from sklearn.model_selection import StratifiedKFold, KFold, train_test_split
from sklearn.metrics import *
from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier
from imblearn.ensemble import RUSBoostClassifier
from sklearn.dummy import DummyClassifier
from lightgbm import LGBMClassifier
from logitboost import LogitBoost
from tabulate import tabulate

parser = argparse.ArgumentParser(description='BIOMAT 2022 Workbench')
parser.add_argument('-i', "--inputfile", dest='inputfile', metavar='<inputfile>', nargs="+", type=str, help='inputfile dataset', required=True)
parser.add_argument('-b', "--seed", dest='seed', metavar='<seed>', type=int, help='seed (default: 1)' , default=1, required=False)
parser.add_argument('-O', "--tuneparams", dest='tuneparams',  action='store_true', required=False)
parser.add_argument('-m', "--method", dest='method', metavar='<method>', type=str, help='classifier name (default: RF, choice: RF|SVM|XGB|LGBM|MLP|LG|EXT|VC|RC)', choices=['VC', 'RF', 'RUS', 'SVM', 'XGB', 'LGBM', 'EXT', 'MLP', 'WNN', 'LG', 'RC'], default='RF', required=False)
parser.add_argument('-G', "--proba", action='store_true', required=False)
parser.add_argument('-f', "--labelfile", dest='labelfile', metavar='<labelfile>', type=str, help='label filename', required=True)
parser.add_argument('-l', "--labelname", dest='labelname', metavar='<labelname>', type=str, help='label name (default label)', default='label', required=False)
parser.add_argument('-x', "--excludelabels", dest='excludelabels', metavar='<excludelabels>', nargs="+", default=[], help='labels to exclude (default NaN, values any list)', required=False)
parser.add_argument('-a', "--aliases", dest='aliases', default="{}", metavar='<aliases>', required=False)
parser.add_argument('-X', "--removefeat", action='store_true', required=False)
parser.add_argument('-F', "--nfeatures", dest='nfeatures',  metavar='<nfeatures>', type=int, help='number of features for elimination (default: 100)' , default=100, required=False)
parser.add_argument('-D', "--tocsv", dest="tocsv", type=str, required=False)
args = parser.parse_args()

seed=args.seed

label_filename = args.labelfile #@param {type:"string"}
labelname = args.labelname #@param {type:"string"}
exclude_labels = [np.nan] + args.excludelabels #@param {type:"raw"}
label_aliases = literal_eval(args.aliases)
#label_aliases = args.aliases
label_file = os.path.join(label_filename)
df_label = pd.read_csv(label_file, sep=',', index_col=0)
if labelname in df_label.columns:
    print(bcolors.HEADER + f'Loading label "{labelname}" from file "{label_file}"...' + bcolors.ENDC)
else:
    print(bcolors.FAIL + f'FAIL: Label name {labelname} is not in the label file{label_filename}!' + bcolors.ENDC)
print(bcolors.OKCYAN + f'Labeling...' + bcolors.ENDC)
print(bcolors.OKGREEN + f'- working on label "{labelname}""...' + bcolors.ENDC)
dup = df_label.index.duplicated().sum()
if dup > 0:
    df_label = df_label[~df_label.index.duplicated(keep='first')]
    print(bcolors.OKGREEN + f'- removing {dup} duplicated genes...' + bcolors.ENDC)
genes = df_label.index.values                                                                    # get genes with defined labels
df_label = df_label[df_label[labelname].isin([np.nan] + exclude_labels) == False]                # drop any row contaning NaN or SC1-SC5 as value
labels = np.unique(df_label[labelname].values)
print(bcolors.OKGREEN + f'- used label values {labels} (excluded {exclude_labels})' + bcolors.ENDC)
for key,newkey in label_aliases.items():
    if key in labels:
        print(bcolors.OKGREEN + f'- replacing label {key} with {newkey}' + bcolors.ENDC)
        df_label = df_label.replace(key, newkey)
selectedgenes = df_label.index.values
print(bcolors.OKGREEN + f'- {len(selectedgenes)} labeled genes over a total of {len(genes)}' + bcolors.ENDC)
print(bcolors.OKGREEN + f'- label distribution: {dict(df_label[labelname].value_counts())}' + bcolors.ENDC)


"""
Load attributes
"""

def intersection(lst1, lst2):
    lst3 = [value for value in lst1 if value in lst2]
    return lst3

attr_file = args.inputfile[0]
print(bcolors.HEADER + f'Loading attribute matrix "{attr_file}" ... ' + bcolors.ENDC, end='')
x = pd.read_csv(attr_file, index_col=0)
x = x.select_dtypes(include=np.number)     # drop non numeric attributes
print(bcolors.HEADER + f'{x.shape}' + bcolors.ENDC)
for attr_file in args.inputfile[1:]:
  print(bcolors.HEADER + f'Loading attribute matrix "{attr_file}" ... ' + bcolors.ENDC, end='')
  df = pd.read_csv(attr_file, index_col=0)
  df = df.select_dtypes(include=np.number)     # drop non numeric attributes
  print(bcolors.HEADER + f'{df.shape}' + bcolors.ENDC)
  x = x.join(df)

selectedgenes = intersection(x.index.to_list(), selectedgenes)
print(bcolors.OKCYAN + f'Reduction...' + bcolors.ENDC)
print(bcolors.OKGREEN + f'- dataset reduced from {x.shape[0]} to {len(selectedgenes)} genes' + bcolors.ENDC)
x = x.loc[selectedgenes]
print(bcolors.OKGREEN + f'- new attribute matrix x{x.shape}' + bcolors.ENDC)

# print label distribution
df_label_reduced = df_label.loc[selectedgenes]
labels = df_label_reduced[labelname].values
distrib = Counter(labels)
encoder = LabelEncoder()
y = encoder.fit_transform(labels)  
classes_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))
rev_classes_mapping = np.array(list(classes_mapping.keys()))
distrib = dict(df_label_reduced[labelname].value_counts())
print(bcolors.OKGREEN + f'- new label distribution:  {distrib}' + bcolors.ENDC)


### set balancing in method paramters
classifier_map = {'RF' : 'RandomForestClassifier', 
                  'MLP': 'MLPClassifier', 
                  'SVM' : 'SVC', 
                  'RUS':  'RUSBoostClassifier',
                  'XGB': 'XGBClassifier',
                  'EXT': 'ExtraTreesClassifier',
                  'LGBM': 'LGBMClassifier',
                  'VC' : 'VotingClassifier',
                  'RC' : 'RidgeClassifier',
                  'LG': 'LogitBoost'}

if args.tuneparams:
  classifiers_args = {
    'RF' : {'random_state' : seed, 'class_weight': 'balanced'}, 
    'MLP': {'random_state' : seed}, 
    'SVM' : {'random_state' : seed, 'class_weight': 'balanced'}, 
    'RUS': {'random_state' : seed},
    'LGBM': {'random_state' : seed, 'class_weight': 'balanced'},
    'EXT': {'random_state' : seed, 'class_weight': 'balanced'},
    'XGB': {'random_state' : seed, 'objective' : "binary:logistic", 'eval_metric' : 'logloss', },
    'VC' : {'estimators': [
        ('xt', ExtraTreesClassifier(random_state = seed, class_weight = 'balanced')), 
        ('xgb', XGBClassifier(random_state = seed, objective = "binary:logistic", eval_metric = 'logloss',  scale_pos_weight=0.2)), 
        ('lgb', LGBMClassifier(random_state = seed, class_weight='balanced'))], 
         'n_jobs' : -1, 
         'voting' :'soft'},
    'RC' : {'random_state' : seed, 'class_weight': 'balanced'},
    'LG' : {'random_state' : seed, 'n_estimators':200 }
  }
  if len(distrib.keys()) == 2:
    first, second = list(distrib.values())
    if first < second:
      factor = round(float(first)/float(second), 2)
    else:
      factor = round(float(second)/float(first), 2)
    classifiers_args["XGB"] = {'random_state' : seed, 'objective' : "binary:logistic", 'eval_metric' : 'logloss', 'scale_pos_weight' : factor}
else:
  classifiers_args = {
    'RF' : {'random_state' : seed}, 
    'MLP': {'random_state' : seed}, 
    'SVM' : {'random_state' : seed}, 
    'RUS': {'random_state' : seed},
    'LGBM': {'random_state' : seed},
    'EXT': {'random_state' : seed},
    'XGB': {'random_state' : seed},
    'VC' : {'estimators': [
        ('xt', ExtraTreesClassifier(random_state = seed)), 
        ('xgb', XGBClassifier(random_state = seed, objective = "binary:logistic", eval_metric = 'logloss')), 
        ('lgb', LGBMClassifier(random_state = seed))], 
         'n_jobs' : -1, 
         'voting' :'hard'},
    'RC' : {'random_state' : seed},
    'LG' : {'random_state' : seed}
  }

## check method compatibility
if x.isnull().sum().sum() > 0 and args.method not in ['LGBM']:
  print(bcolors.FAIL + f'ERR: Method "{args.method}" does not support NaN or Inf input values ... try using -I <imputation-mode>!' + bcolors.ENDC)
  sys.exit(-1)


"""
k-fold cross validation with: SVM, RF, XGB, MLP, RUS
"""

#@title Choose classifier { run: "auto", form-width: "20%" }
method = args.method #@param ["SVM", "XGB", "RF", "MLP", "RUS", "LGB"]
set_seed(seed)
nfolds = 5
kf = StratifiedKFold(n_splits=nfolds, shuffle=True, random_state=seed)
accuracies, mccs = [], []
genes = x.index.values

# feature seelction
if args.removefeat:
  from sklearn.decomposition import PCA
  from sklearn.svm import SVR
  from sklearn.feature_selection import RFE
  from sklearn.tree import DecisionTreeClassifier

  print(bcolors.HEADER + f'Selecting features ...' + bcolors.ENDC)
  #selector = PCA()  
  selector = RFE(estimator=ExtraTreesClassifier(), n_features_to_select=args.nfeatures, step=100, verbose=1)
  selector = selector.fit(x, y)
  selected_features = selector.get_feature_names_out()
  X = selector.transform(x)
  print(bcolors.OKGREEN + f'- New attribute matrix x{x.shape}' + bcolors.ENDC)
else:
  X = x.to_numpy()

if args.tocsv is not None:
    x[selected_features].to_csv(args.tocsv, index=True)
    print(bcolors.HEADER + f'Saving dataset to file {args.tocsv}' + bcolors.ENDC)

nclasses = len(classes_mapping)
cma = np.zeros(shape=(nclasses,nclasses), dtype=np.int)
mm = np.array([], dtype=np.int)
gg = np.array([])
yy = np.array([], dtype=np.int)
probabilities = np.array([])
predictions = np.array([], dtype=int)
columns_names = ["Accuracy","BA", "Sensitivity", "Specificity","MCC", 'CM']
scores = pd.DataFrame(columns=columns_names)
print(bcolors.HEADER + f'Classification with method "{method}"...' + bcolors.ENDC)
print(bcolors.OKGREEN + f'- classifier params: {classifiers_args[method]}' + bcolors.ENDC)
for fold, (train_idx, test_idx) in enumerate(tqdm(kf.split(np.arange(len(X)), y), total=kf.get_n_splits(), desc=bcolors.OKGREEN +  f"{nfolds}-fold")):
    train_x, train_y, test_x, test_y = X[train_idx], y[train_idx], X[test_idx], y[test_idx],
    mm = np.concatenate((mm, test_idx))
    yy = np.concatenate((yy, test_y))
    gg = np.concatenate((gg, genes[test_idx]))
    clf = globals()[classifier_map[args.method]](**classifiers_args[args.method])
    if args.proba:
      probs = clf.fit(train_x, train_y).predict_proba(test_x)
      preds = np.argmax(probs, axis=1)
      probabilities = np.concatenate((probabilities, probs[:, 0]))
    else:
      preds = clf.fit(train_x, train_y).predict(test_x)
    cm = confusion_matrix(test_y, preds)
    cma += cm.astype(int)
    predictions = np.concatenate((predictions, preds))
    scores = scores.append(pd.DataFrame([[accuracy_score(test_y, preds), balanced_accuracy_score(test_y, preds), 
        cm[0,0]/(cm[0,0]+cm[0,1]), cm[1,1]/(cm[1,0]+cm[1,1]), 
        matthews_corrcoef(test_y, preds), cm]], columns=columns_names, index=[fold]))
dfm_scores = pd.DataFrame(scores.mean(axis=0)).T
dfs_scores = pd.DataFrame(scores.std(axis=0)).T
df_scores = pd.DataFrame([f'{row[0]:.3f}Â±{row[1]:.3f}' for row in pd.concat([dfm_scores,dfs_scores], axis=0).T.values.tolist()]).T
df_scores.index=[f'{method}']
df_scores['CM'] = [cma]
df_scores.columns = columns_names
print(bcolors.OKGREEN +  tabulate(df_scores, headers='keys', tablefmt='psql') + bcolors.ENDC)
if args.proba:
  df_results = pd.DataFrame({ 'gene': gg, 'label': yy, 'E_prob': probabilities, 'prediction': predictions})
  df_results = df_results.set_index(['gene'])
  df_results.to_csv('results.csv')
  print(df_results)
